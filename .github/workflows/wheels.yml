name: Wheels

concurrency:
  group: ${{ github.workflow }}-${{ github.event.number }}-${{ github.event.ref }}
  cancel-in-progress: true

# Publish when a (published) GitHub Release is created.
on:
  push:
    branches:
      - master
      - 'releases/**'
      - 'ci/**'
    tags:
      - v*
  pull_request:
    branches:
      - master
      - 'releases/**'
      - 'ci/**'
  release:
    types:
      - published
  # TODO:
  # The scheduled version of this job should really download and install NumPy
  # from scientific-python-nightly-wheels
  schedule:
    - cron:  '12 13 * * 0'

permissions:
  contents: read

jobs:
  build_sdist:
    name: Build source distribution
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          submodules: true

      - uses: actions/setup-python@v5
        name: Install Python
        with:
          python-version: 3.x

      - name: Install APT packages
        if: contains(${{ matrix.os }}, 'ubuntu')
        run: |
          sudo apt update
          # Keep in sync with "Prerequisites" in User's Guide.
          sudo apt install libbz2-dev libhdf5-serial-dev liblzo2-dev
          sudo apt install latexmk texlive-fonts-recommended texlive-latex-recommended texlive-latex-extra texlive-plain-generic

      - name: Install dependencies
        run: |
          # Keep in sync with ``build-system.requires`` in ``pyproject.toml``.
          python -m pip install --require-hashes -r ./.github/workflows/requirements/build-requirements.txt
          python -m pip install --require-hashes -r requirements.txt
          # Keep in sync with ``project.optional-dependencies.doc`` in ``pyproject.toml``.
          python -m pip install --require-hashes -r ./.github/workflows/requirements/optional-requirements.txt

      - name: Build dist (sdist and docs)
        run: make PYTHON=python dist

      - uses: actions/upload-artifact@v4
        with:
          path: dist/*
          name: dist

  build_wheels:
    name: Build ${{ matrix.os }} ${{ matrix.arch }} ${{ matrix.build }} wheels
    runs-on: ${{ matrix.os }}
    env:
      # Keep in sync with "Prerequisites" in User's Guide.
      HDF5_VERSION: 1.14.3  # H5Dchunk_iter needs at least 1.14.1
      MACOSX_DEPLOYMENT_TARGET: "10.9"
    strategy:
      fail-fast: false
      matrix:
        include:
          - os: ubuntu-latest
            arch: x86_64
            build: 'cp*'
          - os: ubuntu-latest
            arch: aarch64
            build: 'cp*'
          - os: macos-13
            arch: x86_64
            build: 'cp*'
          - os: macos-14
            arch: arm64
            build: 'cp*'
          - os: windows-latest
            arch: AMD64
            build: 'cp*'
          # The aarch64 wheels are very slow so split into separate jobs
          - os: ubuntu-latest
            arch: aarch64
            build: 'cp310-*'
          - os: ubuntu-latest
            arch: aarch64
            build: 'cp311-*'
          - os: ubuntu-latest
            arch: aarch64
            build: 'cp312-*'

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          submodules: true

      - uses: actions/setup-python@v5
        name: Install Python on Unix
        with:
          python-version: '3.12'
        if: runner.os != 'Windows'

      - name: Install Python and dependencies on Windows
        uses: mamba-org/setup-micromamba@v1
        with:
          environment-name: build
          create-args: >
            python=3.12 blosc bzip2 hdf5 lz4 lzo snappy zstd zlib pkgconfig
          init-shell: bash powershell
        if: runner.os == 'Windows'

      - uses: docker/setup-qemu-action@v3
        if: runner.os == 'Linux' && matrix.arch != 'x64_64'
        name: Set up QEMU on Linux

      - uses: actions/cache@v4
        id: deps-cache
        with:
          path: hdf5_build
          # Instead of a hashFiles('**/wheels.yml') appended here, just use a counter.
          # It allows us to modify this file without having to constantly rebuild HDF5
          # (which takes almost an hour on Linux emulated aarch64).
          key: ${{ runner.os }}-${{ matrix.arch }}-deps-cache-${{ hashFiles('**/get_hdf5.sh') }}-${{ env.HDF5_VERSION }}-1
        if: runner.os != 'Windows'

      - name: Build dependencies
        env:
          CFLAGS: -g0
          HDF5_DIR: ${{ github.workspace }}/hdf5_build
          HDF5_VERSION: 1.14.3
          MACOSX_DEPLOYMENT_TARGET: "10.9"
        if: runner.os != 'Windows' && steps.deps-cache.outputs.cache-hit != 'true'
        run: |
          mkdir hdf5_build
          if [[ "${{ runner.os }}" = 'Linux' ]]; then
            docker run --rm -e HDF5_DIR=/io/hdf5_build -e CFLAGS="$CFLAGS" -e HDF5_VERSION="$HDF5_VERSION" -v `pwd`:/io:rw quay.io/pypa/manylinux2014_${{ matrix.arch }} /io/ci/github/get_hdf5.sh
          else
            HDF5_DIR=`pwd`/hdf5_build ci/github/get_hdf5.sh
          fi

      - name: Install cibuildwheel
        run: |
          python -m pip install --require-hashes -r ./.github/workflows/requirements/wheels-requirements.txt

      - name: Build ${{ matrix.build }} wheels
        run: |
          python -m cibuildwheel --output-dir wheelhouse
        env:
          CIBW_BUILD: '${{ matrix.build }}'
          CIBW_ARCHS: '${{ matrix.arch }}'

      - name: Copy requirements.txt
        run: |
          cp requirements.txt ./wheelhouse/

      - uses: actions/upload-artifact@v4
        with:
          path: |
            ./wheelhouse/*.whl
            ./wheelhouse/*.txt
          name: cibw-wheels-${{ matrix.os }}-${{ matrix.arch }}-${{ strategy.job-index }}

  twine_check:
    needs: [ build_sdist, build_wheels ]
    name: Twine check
    runs-on: 'ubuntu-latest'

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          submodules: true

      - uses: actions/download-artifact@v4
        with:
          pattern: '*'
          merge-multiple: true
          path: wheelhouse

      - run: ls -al .
      - run: ls -alR ./wheelhouse/
      - run: rm ./wheelhouse/*.txt  # don't upload these

      - name: Install Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Install twine
        run: |
          python -m pip install --require-hashes -r ./.github/workflows/requirements/wheels-requirements.txt

      - name: Check sdist and wheels
        run: |
          python -m twine check wheelhouse/*

      - name: Upload wheel
        uses: scientific-python/upload-nightly-action@b67d7fcc0396e1128a474d1ab2b48aa94680f9fc # 0.5.0
        if: github.repository == 'PyTables/PyTables' && github.event_name == 'schedule'
        with:
          artifacts_path: wheelhouse/artifact
          anaconda_nightly_upload_token: ${{secrets.ANACONDA_ORG_UPLOAD_TOKEN}}
