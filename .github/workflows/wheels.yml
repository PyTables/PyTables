name: Wheels

concurrency:
  group: ${{ github.workflow }}-${{ github.event.number }}-${{ github.event.ref }}
  cancel-in-progress: true

# Publish when a (published) GitHub Release is created.
on:
  push:
    branches:
      - master
      - 'releases/**'
      - 'ci/**'
    tags:
      - v*
  pull_request:
    branches:
      - master
      - 'releases/**'
      - 'ci/**'
  release:
    types:
      - published
  # TODO:
  # The scheduled version of this job should really download and install NumPy
  # from scientific-python-nightly-wheels
  schedule:
    - cron:  '12 13 * * 0'

permissions:
  contents: read

jobs:
  build_sdist:
    name: Build source distribution
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@692973e3d937129bcbf40652eb9f2f61becf3332 # v4.1.7
        with:
          fetch-depth: 0
          submodules: true

      - uses: actions/setup-python@39cd14951b08e74b54015e9e001cdefcf80e669f # v5.1.1
        name: Install Python
        with:
          python-version: 3.x

      - name: Install APT packages
        if: contains(${{ matrix.os }}, 'ubuntu')
        run: |
          sudo apt update
          # Keep in sync with "Prerequisites" in User's Guide.
          sudo apt install libbz2-dev libhdf5-serial-dev
          sudo apt install latexmk texlive-fonts-recommended texlive-latex-recommended texlive-latex-extra texlive-plain-generic

      - name: Install dependencies
        run: |
          # Keep in sync with ``build-system.requires`` in ``pyproject.toml``.
          python -m pip install --require-hashes -r .github/workflows/requirements/build-requirements.txt
          python -m pip install --require-hashes -r requirements.txt
          python -m pip install --require-hashes -r requirements-docs.txt

      - name: Build dist (sdist and docs)
        run: make PYTHON=python dist

      - uses: actions/upload-artifact@0b2256b8c012f0828dc542b3febcab082c67f72b # v4.3.4
        with:
          path: dist/*
          name: dist

  build_wheels:
    name: Build ${{ matrix.os }} ${{ matrix.arch }} ${{ matrix.build }} wheels
    runs-on: ${{ matrix.os }}
    env:
      # Keep in sync with "Prerequisites" in User's Guide.
      HDF5_VERSION: 1.14.6  # H5Dchunk_iter needs at least 1.14.1
      MACOSX_DEPLOYMENT_TARGET: "10.9"
    strategy:
      fail-fast: false
      matrix:
        include:
          - os: ubuntu-latest
            arch: x86_64
            build: 'cp*'
          - os: macos-13
            arch: x86_64
            build: 'cp*'
          - os: macos-14
            arch: arm64
            build: 'cp*'
          - os: windows-latest
            arch: AMD64
            build: 'cp*'
          - os: ubuntu-24.04-arm
            arch: aarch64
            build: 'cp*'

    steps:
      - uses: actions/checkout@692973e3d937129bcbf40652eb9f2f61becf3332 # v4.1.7
        with:
          fetch-depth: 0
          submodules: true

      - uses: actions/setup-python@39cd14951b08e74b54015e9e001cdefcf80e669f # v5.1.1
        name: Install Python on Unix
        with:
          python-version: '3.12'
        if: runner.os != 'Windows'

      - name: Install Python and dependencies on Windows
        uses: mamba-org/setup-micromamba@0dea6379afdaffa5d528b3d1dabc45da37f443fc # v2.0.4
        with:
          environment-name: build
          create-args: >
            python=3.12 blosc c-blosc2 bzip2 hdf5 lz4 snappy zstd zlib pkgconfig
          init-shell: bash powershell
        if: runner.os == 'Windows'

      - uses: actions/cache@1bd1e32a3bdc45362d1e726936510720a7c30a57 # v4.2.0
        id: deps-cache
        with:
          path: hdf5_build
          # Instead of a hashFiles('**/wheels.yml') appended here, just use a counter.
          # It allows us to modify this file without having to constantly rebuild HDF5
          # (which takes almost an hour on Linux emulated aarch64).
          key: ${{ runner.os }}-${{ matrix.arch }}-deps-cache-${{ hashFiles('**/get_hdf5.sh') }}-${{ env.HDF5_VERSION }}-1
        if: runner.os != 'Windows'

      - name: Build dependencies
        env:
          CFLAGS: -g0
          HDF5_DIR: ${{ github.workspace }}/hdf5_build
          MACOSX_DEPLOYMENT_TARGET: "10.9"
        if: runner.os != 'Windows' && steps.deps-cache.outputs.cache-hit != 'true'
        run: |
          mkdir hdf5_build
          if [[ "${{ runner.os }}" = 'Linux' ]]; then
            docker run --rm -e HDF5_DIR=/io/hdf5_build -e CFLAGS="$CFLAGS" -e HDF5_VERSION="$HDF5_VERSION" -v `pwd`:/io:rw quay.io/pypa/manylinux2014_${{ matrix.arch }} /io/ci/github/get_hdf5.sh
          else
            HDF5_DIR=`pwd`/hdf5_build ci/github/get_hdf5.sh
          fi

      - name: Install cibuildwheel
        run: |
          python -m pip install --require-hashes -r ./.github/workflows/requirements/wheels-requirements.txt

      - name: Build ${{ matrix.build }} wheels
        run: |
          python -m cibuildwheel --output-dir wheelhouse
        env:
          CIBW_BUILD: '${{ matrix.build }}'
          CIBW_ARCHS: '${{ matrix.arch }}'

      - name: Copy requirements.txt
        run: |
          cp requirements.txt ./wheelhouse/

      - uses: actions/upload-artifact@0b2256b8c012f0828dc542b3febcab082c67f72b # v4.3.4
        with:
          path: |
            ./wheelhouse/*.whl
            ./wheelhouse/*.txt
          name: cibw-wheels-${{ matrix.os }}-${{ matrix.arch }}-${{ strategy.job-index }}

  twine_check:
    needs: [ build_sdist, build_wheels ]
    name: Twine check
    runs-on: 'ubuntu-latest'

    steps:
      - uses: actions/checkout@692973e3d937129bcbf40652eb9f2f61becf3332 # v4.1.7
        with:
          fetch-depth: 0
          submodules: true

      - uses: actions/download-artifact@fa0a91b85d4f404e444e00e005971372dc801d16 # v4.1.8
        with:
          pattern: '*'
          merge-multiple: true
          path: wheelhouse

      - name: List downloaded artifacts
        run: ls -alR ./wheelhouse/

      - name: Install Python
        uses: actions/setup-python@39cd14951b08e74b54015e9e001cdefcf80e669f # v5.1.1
        with:
          python-version: '3.x'

      - name: Install twine
        run: |
          python -m pip install --require-hashes -r ./.github/workflows/requirements/wheels-requirements.txt

      - name: Check sdist and wheels
        run: |
          python -m twine check *.whl tables-*.tar.gz
        working-directory: wheelhouse

      - name: Upload wheel
        uses: scientific-python/upload-nightly-action@82396a2ed4269ba06c6b2988bb4fd568ef3c3d6b # 0.6.1
        if: github.repository == 'PyTables/PyTables' && github.event_name == 'schedule'
        with:
          artifacts_path: wheelhouse
          anaconda_nightly_upload_token: ${{secrets.ANACONDA_ORG_UPLOAD_TOKEN}}
